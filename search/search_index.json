{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#my-home-lab-repository","title":"\ud83d\ude80 My home-lab repository","text":"<p>\u2728 Hosted with k0s &amp; Talos</p> <p>\u2728 Managed by ArgoCD</p> <p>\u2728 Powered by Renovate and GitHub</p> <p>INFRASTRUCTURE</p> <p> </p> <p>TOOLING HELM VERSION</p> <p> </p> <p> </p> <p>This project utilizes Infrastructure as Code and GitOps to automate provisioning, operating, and updating self-hosted services in my homelab.</p>"},{"location":"VPN/wireguard/","title":"WireGuard","text":""},{"location":"VPN/wireguard/#privileges","title":"Privileges","text":"<p>WireGuard will need some specific privileges to be able to NAT traffic and redirect your requests. Consider using <code>sysctls</code> options on your nodes. You need to specify it at kubelet level:</p> <ul> <li><code>net.ipv4.ip_forward</code></li> <li><code>net.ipv4.conf.all.src_valid_mark</code></li> </ul> <p>For example in <code>k0s</code> :</p> <pre><code>---\napiVersion: k0sctl.k0sproject.io/v1beta1\nkind: Cluster\nmetadata:\n  name: fullstack\n  user: admin\nspec:\n  hosts:\n    - role: single\n      installFlags:\n        - --debug\n        - --disable-components=autopilot,helm,windows-node,konnectivity-server\n        - --kubelet-extra-args=\"--allowed-unsafe-sysctls=net.ipv4.ip_forward,net.ipv4.conf.all.src_valid_mark\"\n</code></pre> <p>And your also need to specify it at pod level as well as <code>NET_ADMIN</code> capability:</p> <pre><code>spec:\n  automountServiceAccountToken: false\n  containers:\n    - image: wgportal/wg-portal:v2\n      imagePullPolicy: IfNotPresent\n      name: wg-portal\n      securityContext:\n        capabilities:\n          add:\n            - NET_ADMIN\n  securityContext:\n    sysctls:\n      - name: net.ipv4.ip_forward\n        value: '1'\n      - name: net.ipv4.conf.all.src_valid_mark\n        value: '1'\n</code></pre>"},{"location":"argocd/argocd/","title":"GitOps-core","text":"<p>[!CAUTION] This structure is opinionated and results from multiple experiences using ArgoCD in enterprise-grade environments.</p>"},{"location":"argocd/argocd/#overview","title":"Overview","text":"<p>This Git repository serves as the central ArgoCD repository, containing the definition of the ArgoCD deployment itself, as well as the various ArgoCD objects (<code>Application</code>, <code>ApplicationSet</code>, <code>AppProject</code>, etc.).</p> <p>The installation of ArgoCD follows the App of Apps pattern, a recommended best practice for managing GitOps deployments at scale.</p>"},{"location":"argocd/argocd/#repository-structure","title":"Repository Structure","text":"<p>Below is the directory structure of the <code>gitops</code> repository:</p> <pre><code>gitops\n\u251c\u2500\u2500 bootstrap\n\u2502   \u2514\u2500\u2500 kustomization.yaml\n\u251c\u2500\u2500 core\n\u2502   \u251c\u2500\u2500 appProjects\n\u2502   \u251c\u2500\u2500 apps\n\u2502   \u2514\u2500\u2500 repos\n\u251c\u2500\u2500 local-storage\n\u2502   \u251c\u2500\u2500 adguard-data\n\u2502   \u251c\u2500\u2500 headscale-data\n\u2502   \u2514\u2500\u2500 vault-data\n\u2514\u2500\u2500 manifests\n    \u251c\u2500\u2500 adguard\n    \u251c\u2500\u2500 authentik\n    \u251c\u2500\u2500 crowdsec\n    \u251c\u2500\u2500 external-secrets\n    \u251c\u2500\u2500 headscale\n    \u251c\u2500\u2500 homarr\n    \u251c\u2500\u2500 local-path-provisioner\n    \u251c\u2500\u2500 metallb\n    \u251c\u2500\u2500 traefik\n    \u251c\u2500\u2500 vault\n    \u2514\u2500\u2500 wireguard\n</code></pre>"},{"location":"argocd/argocd/#directory-breakdown","title":"Directory Breakdown","text":"<ul> <li><code>bootstrap/</code>: Contains the ArgoCD installation manifests, which can be managed via <code>kustomization.yaml</code> or Helm charts.</li> <li><code>core/</code>: Includes core ArgoCD resources such as <code>Application</code>, <code>ApplicationSet</code>, and <code>AppProject</code> definitions.</li> <li><code>local-storage/</code> (optional): Used for applications requiring persistent storage, mapped via a local-path provisioner.</li> <li><code>manifests/</code>: Stores Kubernetes manifests and Helm configurations for different cluster services and applications.</li> </ul>"},{"location":"argocd/argocd/#multi-environment-setup","title":"Multi-Environment Setup","text":"<p>For a structured multi-environment approach, the <code>manifests</code> directory is organized as follows:</p> <pre><code>gitops/manifests/\n\u251c\u2500\u2500 metallb\n\u2502   \u251c\u2500\u2500 k0s\n\u2502   \u2502   \u251c\u2500\u2500 Chart.yaml\n\u2502   \u2502   \u251c\u2500\u2500 k0s-values.yaml\n\u2502   \u2502   \u2514\u2500\u2500 templates\n\u2502   \u251c\u2500\u2500 talos\n\u2502   \u2502   \u251c\u2500\u2500 Chart.yaml\n\u2502   \u2502   \u251c\u2500\u2500 talos-values.yaml\n\u2502   \u2502   \u2514\u2500\u2500 templates\n\u2502   \u2514\u2500\u2500 values\n\u2502       \u2514\u2500\u2500 common-values.yaml\n\u2514\u2500\u2500 traefik\n    \u251c\u2500\u2500 k0s\n    \u2502   \u251c\u2500\u2500 Chart.yaml\n    \u2502   \u251c\u2500\u2500 k0s-values.yaml\n    \u2502   \u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 talos\n    \u2502   \u251c\u2500\u2500 Chart.yaml\n    \u2502   \u251c\u2500\u2500 talos-values.yaml\n    \u2502   \u2514\u2500\u2500 templates\n    \u2514\u2500\u2500 values\n        \u2514\u2500\u2500 common-values.yaml\n</code></pre> <p>Each application directory contains subdirectories for different environments (<code>k0s</code>, <code>talos</code>), allowing environment-specific Helm values while maintaining shared configurations in <code>common-values.yaml</code>.</p>"},{"location":"argocd/argocd/#applicationset-usage","title":"ApplicationSet Usage","text":"<p>To efficiently deploy applications while supporting multiple environments, <code>ApplicationSet</code> is utilized:</p> <pre><code>---\napiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: cert-manager\n  namespace: argocd\n  annotations:\n    argocd.argoproj.io/manifest-generate-paths: .;../values\nspec:\n  goTemplate: true\n  generators:\n    - git:\n        repoURL: 'https://github.com/ixxeL-DevOps/fullstack.git'\n        revision: main\n        directories:\n          - path: 'gitops/manifests/cert-manager/*'\n            exclude: false\n          - path: 'gitops/manifests/cert-manager/values/*'\n            exclude: true\n  template:\n    metadata:\n      name: 'cert-manager-{{ .path.basenameNormalized }}'\n      annotations:\n        argocd.argoproj.io/manifest-generate-paths: .;../values\n    spec:\n      project: infra-security\n      destination:\n        name: '{{ .path.basenameNormalized }}'\n        namespace: cert-manager\n      sources:\n        - path: 'gitops/manifests/cert-manager/{{ .path.basenameNormalized }}'\n          repoURL: https://github.com/ixxeL-DevOps/fullstack.git\n          targetRevision: main\n          helm:\n            valueFiles:\n              - $values/gitops/manifests/cert-manager/values/common-values.yaml\n              - $values/gitops/manifests/cert-manager/{{ .path.basenameNormalized }}/{{ .path.basenameNormalized }}-values.yaml\n        - repoURL: https://github.com/ixxeL-DevOps/fullstack.git\n          targetRevision: main\n          ref: values\n      syncPolicy:\n        automated:\n          prune: true\n          selfHeal: true\n        syncOptions:\n          - Validate=true\n          - PruneLast=false\n          - RespectIgnoreDifferences=true\n          - Replace=false\n          - ApplyOutOfSyncOnly=true\n          - CreateNamespace=true\n          - ServerSideApply=true\n</code></pre> <p>The ApplicationSet is annotated following ArgoCD optimization recommendations.</p>"},{"location":"argocd/argocd/#key-features","title":"Key Features","text":"<ul> <li>Multi-environment support: Uses directory-based environment segregation.</li> <li>Hierarchical Helm values: Supports multiple value files (<code>common-values.yaml</code> and environment-specific values).</li> <li>Automated synchronization: Ensures ArgoCD keeps applications up-to-date and reconciled with Git.</li> <li>Flexible exclusions: Allows selective inclusion of manifests while ignoring specific files if necessary.</li> </ul> <p>By leveraging <code>ApplicationSet</code>, managing deployments across multiple clusters and environments becomes more scalable and maintainable.</p>"},{"location":"authentication/oidc/","title":"OIDC","text":""},{"location":"authentication/oidc/#vault","title":"Vault","text":"<p>Blueprint for Vault OIDC auth :</p> <pre><code>---\nversion: 1\nmetadata:\n  name: fullstack-vault\nentries:\n  - id: provider\n    model: authentik_providers_oauth2.oauth2provider\n    state: 'present'\n    identifiers:\n      name: fullstack-vault\n    attrs:\n      authorization_flow: !Find [authentik_flows.flow, [slug, default-provider-authorization-implicit-consent]]\n      invalidation_flow: !Find [authentik_flows.flow, [slug, default-invalidation-flow]]\n      signing_key: !Find [authentik_crypto.certificatekeypair, [name, authentik Self-signed Certificate]]\n      client_type: confidential\n      redirect_uris:\n        - url: https://vault.k0s-fullstack.fredcorp.com/oidc/callback\n          matching_mode: strict\n        - url: https://vault.k0s-fullstack.fredcorp.com/ui/vault/auth/oidc/oidc/callback\n          matching_mode: strict\n\n      access_code_validity: minutes=1\n      access_token_validity: hours=1\n      refresh_token_validity: days=30\n\n      sub_mode: hashed_user_id\n      property_mappings:\n        - !Find [authentik_core.propertymapping, [name, \"authentik default OAuth Mapping: OpenID 'openid'\"]]\n        - !Find [authentik_core.propertymapping, [name, \"authentik default OAuth Mapping: OpenID 'profile'\"]]\n        - !Find [authentik_core.propertymapping, [name, \"authentik default OAuth Mapping: OpenID 'email'\"]]\n\n  - id: application\n    model: authentik_core.application\n    state: 'present'\n    identifiers:\n      name: 'fullstack-vault'\n    attrs:\n      name: fullstack-vault\n      group: Infrastructure\n      meta_description: HashiCorp Vault\n      provider: !Find [authentik_providers_oauth2.oauth2provider, [name, fullstack-vault]]\n      policy_engine_mode: any\n      slug: fullstack-vault\n</code></pre> <p>Vault must be configured for OIDC provider with Authentik :</p> <ul> <li><code>ca.pem</code> : is the CA chain for the Authentik certificate</li> <li><code>fullstack-vault</code> : is the Authentik application slug</li> </ul> <pre><code>vault login -tls-skip-verify -address=https://vault.k0s-fullstack.fredcorp.com\n\nvault write -tls-skip-verify -address=https://vault.k0s-fullstack.fredcorp.com auth/oidc/config oidc_discovery_url=\"https://authentik.k0s-fullstack.fredcorp.com/application/o/fullstack-vault/\" oidc_client_id=\"&lt;authentik-provider-client-id&gt;\" oidc_client_secret=\"&lt;authentik-provider-client-secret&gt;\" default_role=\"reader\" oidc_discovery_ca_pem=@ca.pem\n\nvault write -tls-skip-verify -address=https://vault.k0s-fullstack.fredcorp.com auth/oidc/role/reader bound_audiences=\"&lt;authentik-provider-client-id&gt;\" allowed_redirect_uris=\"https://vault.k0s-fullstack.fredcorp.com/ui/vault/auth/oidc/oidc/callback\" allowed_redirect_uris=\"https://vault.k0s-fullstack.fredcorp.com/oidc/callback\" user_claim=\"sub\" policies=\"reader\"\n</code></pre> <p>To manage groups, you can configure following:</p> <pre><code>vault write -tls-skip-verify -address=https://vault.k0s-fullstack.fredcorp.com auth/oidc/role/reader bound_audiences=\"&lt;authentik-provider-client-id&gt;\" allowed_redirect_uris=\"https://vault.k0s-fullstack.fredcorp.com/ui/vault/auth/oidc/oidc/callback\" allowed_redirect_uris=\"https://vault.k0s-fullstack.fredcorp.com/oidc/callback\" us\ner_claim=\"sub\" policies=\"reader\" groups_claim=\"groups\" oidc_scopes=[ \"openid profile email\" ]\n\nvault write -tls-skip-verify -address=https://vault.k0s-fullstack.fredcorp.com identity/group name=\"administrator\" policies=\"administrator\" type=\"external\" metadata=responsibility=\"Manage Vault instance\"\n</code></pre> <p>Access information with:</p> <pre><code>vault auth list -tls-skip-verify -address=https://vault.k0s-fullstack.fredcorp.com\nvault read -tls-skip-verify -address=https://vault.k0s-fullstack.fredcorp.com identity/group/name/administrator\n</code></pre> <p>Link to Authentik:</p> <pre><code>vault write -tls-skip-verify -address=https://vault.k0s-fullstack.fredcorp.com identity/group-alias mount_accessor=\"auth_oidc_b59bc9a6\" canonical_id=\"cbd6e4ac-e516-4424-742a-41a978252bb6\" name=\"group name in authentik\"\n</code></pre> <p>You need to Create an Authentik group named <code>group name in authentik</code> and a Vault policy for admins like that :</p> <pre><code>path \"*\" {\n  capabilities = [\"create\", \"read\", \"update\", \"delete\", \"list\", \"sudo\"]\n}\n</code></pre>"},{"location":"authentication/oidc/#wireguard-portal","title":"WireGuard Portal","text":"<p>Wiregard portal relies on <code>is_admin</code> property to make user admin of the server. This property can be passed as an OIDC claim with a specific script in <code>Scope Mapping</code> and then added to the provider:</p> <pre><code>return {\n  \"is_admin\": ak_is_group_member(request.user, name=\"Wireguard admins\")\n}\n</code></pre> <p>The configuration need to be made as OIDC :</p> <pre><code>config:\n  core:\n    admin_user: '${ADMIN_USER}'\n    admin_password: '${ADMIN_PASSWORD}'\n    import_existing: false\n    create_default_peer: true\n    self_provisioning_allowed: true\n\n  auth:\n    callback_url_prefix: https://wireguard.k0s-fullstack.fredcorp.com/api/v0\n    oidc:\n      - id: Authentik\n        provider_name: Authentik\n        display_name: OIDC Authentik\n        base_url: https://authentik.k0s-fullstack.fredcorp.com/application/o/fullstack-wireguard/\n        client_id: '${OIDC_CLIENT_ID}'\n        client_secret: '${OIDC_CLIENT_SECRET}'\n        extra_scopes:\n          - profile\n          - email\n          - openid\n          - is_admin\n        field_map:\n          email: email\n          user_identifier: email\n          is_admin: is_admin\n        registration_enabled: true\n        log_user_info: false\n</code></pre> <p>The variables here can be injected with kubernetes <code>Secret</code> in <code>values.yaml</code> file:</p> <pre><code># OIDC secret config\nenvFrom:\n  - secretRef:\n      name: oidc-wireguard\n  - secretRef:\n      name: admin-wireguard\n</code></pre> <p>In Authentik, you need to specify the <code>is_admin</code> in the provider properties:</p> <pre><code>- id: provider\n  model: authentik_providers_oauth2.oauth2provider\n  state: present\n  identifiers:\n    name: fullstack-wireguard\n  attrs:\n    authorization_flow: !Find [authentik_flows.flow, [slug, default-provider-authorization-implicit-consent]]\n    invalidation_flow: !Find [authentik_flows.flow, [slug, default-invalidation-flow]]\n    signing_key: !Find [authentik_crypto.certificatekeypair, [name, authentik Self-signed Certificate]]\n    client_type: confidential\n    redirect_uris:\n      - url: https://wireguard.k0s-fullstack.fredcorp.com/api/v0/auth/login/authentik/callback\n        matching_mode: strict\n\n    access_code_validity: minutes=1\n    access_token_validity: hours=1\n    refresh_token_validity: hours=1\n\n    sub_mode: hashed_user_id\n    property_mappings:\n      - !Find [authentik_core.propertymapping, [name, \"authentik default OAuth Mapping: OpenID 'openid'\"]]\n      - !Find [authentik_core.propertymapping, [name, \"authentik default OAuth Mapping: OpenID 'profile'\"]]\n      - !Find [authentik_core.propertymapping, [name, \"authentik default OAuth Mapping: OpenID 'email'\"]]\n      - !Find [authentik_core.propertymapping, [name, \"OAuth mapping: OpenID 'is_admin' for Wireguard\"]]\n\n  - model: authentik_providers_oauth2.scopemapping\n    identifiers:\n      name: \"OAuth mapping: OpenID 'is_admin' for Wireguard\"\n    attrs:\n      description: is_admin claim for Wireguard Portal OIDC\n      expression: |\n        return {\n          \"is_admin\": ak_is_group_member(request.user, name=\"Wireguard admins\")\n        }\n      name: wireguard-is-admin\n      scope_name: is_admin\n</code></pre>"},{"location":"authentication/oidc/#homarr","title":"Homarr","text":"<p>Homarr is easy to integrate with OIDC. You just need to specify some variables in the <code>env</code> key from <code>values.yaml</code> file:</p> <pre><code>env:\n  AUTH_PROVIDERS: credentials,oidc\n  AUTH_SESSION_EXPIRY_TIME: 1h\n  AUTH_OIDC_AUTO_LOGIN: 'false'\n  AUTH_OIDC_ISSUER: https://authentik.k0s-fullstack.fredcorp.com/application/o/fullstack-homarr/\n  AUTH_OIDC_URI: 'https://authentik.k0s-fullstack.fredcorp.com/application/o/authorize/'\n  AUTH_OIDC_CLIENT_NAME: Authentik\n  AUTH_OIDC_SCOPE_OVERWRITE: openid email profile groups\n  AUTH_OIDC_GROUPS_ATTRIBUTE: groups\n  AUTH_LOGOUT_REDIRECT_URL: https://homarr.k0s-fullstack.fredcorp.com/auth/login\n</code></pre> <p>And you can used <code>Secret</code> to inject ClientID and ClientSecret for OIDS auth:</p> <pre><code>envSecrets:\n  authOidcCredentials:\n    existingSecret: auth-oidc-secret\n    oidcClientId: oidc-client-id\n    oidcClientSecret: oidc-client-secret\n</code></pre> <p>Variable <code>NODE_TLS_REJECT_UNAUTHORIZED: '0'</code> can be used in case certificates are not recognized. Th</p>"},{"location":"authentication/proxy-auth/","title":"Forward Auth","text":""},{"location":"authentication/proxy-auth/#reverse-proxy-setup-traefik","title":"Reverse-Proxy setup : Traefik","text":""},{"location":"authentication/proxy-auth/#in-cluster-setup","title":"In-cluster setup","text":"<p>Traefik needs to be configured to act as a reverse proxy with Authentik. Use this <code>Middleware</code> with the added <code>authorization</code> header from the official documentation to be able to pass Basic Auth headers in case you need to login transparently to non OIDC servers.</p> <pre><code>---\napiVersion: traefik.io/v1alpha1\nkind: Middleware\nmetadata:\n  name: authentik\nspec:\n  forwardAuth:\n    address: http://ak-outpost-authentik-embedded-outpost.authentik:9000/outpost.goauthentik.io/auth/traefik\n    trustForwardHeader: true\n    authResponseHeaders:\n      - X-authentik-username\n      - X-authentik-groups\n      - X-authentik-entitlements\n      - X-authentik-email\n      - X-authentik-name\n      - X-authentik-uid\n      - X-authentik-jwt\n      - X-authentik-meta-jwks\n      - X-authentik-meta-outpost\n      - X-authentik-meta-provider\n      - X-authentik-meta-app\n      - X-authentik-meta-version\n      - authorization\n</code></pre> <p>The field <code>address</code> should point to your authentik outpost service inside the cluster:</p> <pre><code>NAME                                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE\nak-outpost-authentik-embedded-outpost   ClusterIP   10.96.153.169    &lt;none&gt;        9000/TCP,9300/TCP,9443/TCP   5d16h\nauthentik-k0s-postgresql                ClusterIP   10.97.192.194    &lt;none&gt;        5432/TCP                     4d15h\nauthentik-k0s-postgresql-hl             ClusterIP   None             &lt;none&gt;        5432/TCP                     4d15h\nauthentik-k0s-redis-headless            ClusterIP   None             &lt;none&gt;        6379/TCP                     4d15h\nauthentik-k0s-redis-master              ClusterIP   10.101.158.29    &lt;none&gt;        6379/TCP                     4d15h\nauthentik-k0s-server                    ClusterIP   10.111.223.218   &lt;none&gt;        80/TCP,443/TCP               4d15h\n</code></pre> <p>You also need to add annotation to Traefik <code>Ingress</code>. The pattern here is <code>&lt;namespace&gt;-&lt;middleware-name&gt;@kubernetescrd</code> :</p> <pre><code>annotations:\n  traefik.ingress.kubernetes.io/router.middlewares: traefik-authentik@kubernetescrd\n</code></pre> <p>For <code>IngressRoute</code> you have to specify differently :</p> <pre><code>---\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: traefik-k0s-dashboard\nspec:\n  entryPoints:\n    - web\n    - websecure\n  routes:\n    - kind: Rule\n      match: Host(`traefik.k0s-fullstack.fredcorp.com`)\n      middlewares:\n        - name: authentik\n          namespace: traefik\n      priority: 10\n      services:\n        - kind: TraefikService\n          name: api@internal\n          namespace: traefik\n    - kind: Rule\n      match: Host(`traefik.k0s-fullstack.fredcorp.com`) &amp;&amp; PathPrefix(`/outpost.goauthentik.io/`)\n      priority: 15\n      services:\n        - kind: Service\n          name: ak-outpost-authentik-embedded-outpost\n          namespace: authentik\n          port: 9000\n</code></pre>"},{"location":"certificates/certmanager/","title":"Cert-Manager","text":""},{"location":"certificates/certmanager/#installation","title":"Installation","text":"<p>Cert-manager can be used to handle certificates lifecycle in your cluster. <code>cert-manager</code> and <code>trust-manager</code> should be installed to get a complete lifycle management.</p>"},{"location":"certificates/certmanager/#configuration","title":"Configuration","text":"<p>Cert-manager must be bound to your CA, in our case this is HC Vault. The clusterIssuer represent the CA and should point to the <code>Intermediate</code> PKI and get a <code>kubernetes</code> Vault authentication.</p> <pre><code>---\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: fredcorp-ca\nspec:\n  vault:\n    server: https://vault.k0s-fullstack.fredcorp.com\n    path: pki_int/sign/fredcorp.com\n    caBundleSecretRef:\n      key: ca.crt\n      name: root-ca-chain\n    auth:\n      kubernetes:\n        mountPath: /v1/auth/kubernetes\n        role: certmanager-vault-auth-k0s\n        secretRef:\n          name: certmanager-vault-auth-k0s\n          key: token\n</code></pre> <p>The <code>caBundleSecretRef</code> should point to the chain certificate to trust Vault server.</p> <p>To be able to get the cluster issuer permissions to connect to Vault PKI, use <code>ServiceAccount</code> and <code>ClusterRoleBinding</code> :</p> <pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: tokenreview-binding-certmanager\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: system:auth-delegator\nsubjects:\n  - kind: ServiceAccount\n    name: certmanager-vault-auth-k0s\n    namespace: cert-manager\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: certmanager-vault-auth-k0s\n---\napiVersion: v1\nkind: Secret\ntype: kubernetes.io/service-account-token\nmetadata:\n  name: certmanager-vault-auth-k0s\n  annotations:\n    kubernetes.io/service-account.name: 'certmanager-vault-auth-k0s'\n</code></pre> <p>Then you need to configure the HC Vault server. First login:</p> <pre><code>vault login -method=token -tls-skip-verify -address=https://vault.k0s-fullstack.fredcorp.com\n</code></pre> <p>Get the current kubernetes cluster CA certificate :</p> <pre><code>kubectl config view --raw --minify --flatten -o jsonpath='{.clusters[].cluster.certificate-authority-data}' | base64 --decode &gt; ca.crt\n</code></pre> <p>Get the <code>ServiceAccount</code> generated token :</p> <pre><code>TOKEN=\"$(kubectl get secret -n cert-manager certmanager-vault-auth-k0s -o jsonpath='{.data.token}' | base64 -d)\"\n</code></pre> <p>Write the entry in Vault kubernetes Auth:</p> <pre><code>vault write -tls-skip-verify -address=https://vault.k0s-fullstack.fredcorp.com \\\n            auth/kubernetes/config token_reviewer_jwt=\"$TOKEN\" \\\n            kubernetes_host=\"https://k0s.fullstack.fredcorp.com:6443\" \\\n            kubernetes_ca_cert=@ca.crt\n</code></pre> <p>And then create the associated role :</p> <pre><code>vault write -tls-skip-verify -address=https://vault.k0s-fullstack.fredcorp.com \\\n            auth/kubernetes/role/certmanager-vault-auth-k0s \\\n            bound_service_account_names=certmanager-vault-auth-k0s \\\n            bound_service_account_namespaces=cert-manager \\\n            policies=pki_fredcorp ttl=24h\n</code></pre> <p>You also need to create an associated policy, here named <code>pki_fredcorp</code>:</p> <pre><code>path \"*\" {\n    capabilities = [\"create\", \"read\", \"update\", \"delete\", \"list\", \"sudo\"]\n}\n\npath \"pki_int*\"\n{\n  capabilities = [\"read\", \"list\"]\n}\n\npath \"pki_int/roles/fredcorp.com\"\n{\n  capabilities = [\"create\", \"update\"]\n}\n\npath \"pki_int/sign/fredcorp.com\"\n{\n  capabilities = [\"create\", \"update\"]\n}\n\npath \"pki_int/issue/fredcorp.com\"\n{\n  capabilities = [\"create\", \"update\", \"read\", \"list\"]\n}\n</code></pre> <p>Then refresh the <code>ClusterIssuer</code> it should be valid and working:</p> <pre><code>NAME          READY   AGE\nfredcorp-ca   True    24s\n</code></pre>"},{"location":"certificates/certmanager/#bundles","title":"Bundles","text":"<p>Trust-manager handles CA Bundles to make it easier for you to manage cluster trusted certificates.</p> <p>You can use a Bundle and reference a secret as source of certificates. Target can be either <code>configMap</code> or <code>secret</code>.</p> <pre><code>---\napiVersion: trust.cert-manager.io/v1alpha1\nkind: Bundle\nmetadata:\n  name: fredcorp-ca-chain\nspec:\n  sources:\n    - useDefaultCAs: false\n    - secret:\n        name: 'root-ca-chain'\n        key: 'ca.crt'\n  target:\n    secret:\n      key: 'fredcorp-ca-chain.pem'\n    additionalFormats:\n      pkcs12:\n        key: 'fredcorp-ca-chain.p12'\n        password: ''\n    namespaceSelector:\n      matchLabels:\n        bundle.chain/inject: 'enabled'\n</code></pre>"},{"location":"certificates/tls/","title":"TLS encryption","text":""},{"location":"certificates/tls/#reverse-proxy-encryption-wildcard-certificate","title":"Reverse Proxy encryption : wildcard certificate","text":"<p>Traefik can handle TLS traffic with enforced HTTPS redirection and TLS Termination. You need to specify it inb Traefik configuration with rule for redirection and TLSStore.</p> <p>here is the <code>value.yaml</code> file for <code>TLSStore</code> configuration:</p> <pre><code>tlsStore:\n  default:\n    defaultCertificate:\n      secretName: k0s-fullstack-wildcard\n</code></pre> <p>TLSStore:</p> <pre><code>apiVersion: traefik.io/v1alpha1\nkind: TLSStore\nmetadata:\n  name: default\n  namespace: traefik\nspec:\n  defaultCertificate:\n    secretName: k0s-fullstack-wildcard\n</code></pre> <p>And provision the <code>Secret</code> with an <code>ExternalSecret</code> :</p> <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: k0s-fullstack-wildcard\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: admin\n    kind: ClusterSecretStore\n  target:\n    name: k0s-fullstack-wildcard\n    creationPolicy: Owner\n    template:\n      type: kubernetes.io/tls\n      data:\n        tls.crt: '{{ .p12 | pkcs12cert  }}'\n        tls.key: '{{ .p12 | pkcs12key }}'\n  data:\n    - secretKey: p12\n      remoteRef:\n        conversionStrategy: Default\n        decodingStrategy: Base64\n        metadataPolicy: None\n        key: wildcard/k0s-fullstack\n        property: p12\n</code></pre> <p>And finally enforce TLS redirection in <code>values.yaml</code> file :</p> <pre><code>ports:\n  web:\n    redirections:\n      entryPoint:\n        to: websecure\n        scheme: https\n</code></pre> <p>This configuration will enforce HTTPS traffic to all endpoints behing Traefik with a wildcard certificate managed by Traefik.</p>"},{"location":"certificates/tls/#tls-re-encryption","title":"TLS re-encryption","text":"<p>The best configuration is to enable TLS re-encryption to the final backend. With a combination of Certmanager and Traefik you can achieve this quite easily.</p> <p>You just need to add specific annotations to <code>Ingress</code> resources to re-encrypt traffic:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    cert-manager.io/cluster-issuer: fredcorp-ca\n    cert-manager.io/common-name: homarr.k0s-fullstack.fredcorp.com\n    traefik.ingress.kubernetes.io/router.entrypoints: websecure\n    traefik.ingress.kubernetes.io/service.scheme: https\n  name: homarr-k0s\n  namespace: homarr\nspec:\n  ingressClassName: traefik\n  rules:\n    - host: homarr.k0s-fullstack.fredcorp.com\n      http:\n        paths:\n          - backend:\n              service:\n                name: homarr-k0s\n                port:\n                  number: 7575\n            path: /\n            pathType: Prefix\n  tls:\n    - hosts:\n        - homarr.k0s-fullstack.fredcorp.com\n      secretName: homarr-tls-cert\n</code></pre> <p>Annotation for Cert-manager to automatically manage certificate provisionning and renewal :</p> <pre><code>cert-manager.io/cluster-issuer: fredcorp-ca\ncert-manager.io/common-name: homarr.k0s-fullstack.fredcorp.com\n</code></pre> <p>Annotation for Traefik to enforce TLS re-encryption:</p> <pre><code>traefik.ingress.kubernetes.io/router.entrypoints: websecure\ntraefik.ingress.kubernetes.io/service.scheme: https\n</code></pre>"},{"location":"cluster/k0s/","title":"k0s Cluster Installation Guide (Single Node)","text":"<p>This document details the installation and configuration of a single-node k0s cluster for my home lab environment. It is based on the provided <code>k0sctl.yaml</code> file and explains the technical choices made. Additionally, a Taskfile is used to simplify cluster management tasks.</p>"},{"location":"cluster/k0s/#cluster-overview","title":"\ud83c\udfd7\ufe0f Cluster Overview","text":"<p>The cluster is a single-node Kubernetes cluster running on a small home server. It uses k0s, a lightweight Kubernetes distribution, and stores its state in Kine instead of etcd.</p>"},{"location":"cluster/k0s/#key-features","title":"\ud83d\udd39 Key Features:","text":"<ul> <li>Data Storage: <code>kine</code> (instead of etcd, more lightweight for a home lab)</li> <li>CNI (Networking): <code>kube-router</code></li> <li>SSH Management: Connection via user <code>fred</code></li> <li>Disabled Components: <code>autopilot</code>, <code>helm</code>, <code>windows-node</code>, <code>konnectivity-server</code> for optimization</li> <li>Security: Certain unsafe <code>sysctls</code> are allowed for advanced routing (<code>net.ipv4.ip_forward</code>, <code>net.ipv4.conf.all.src_valid_mark</code>), particularly for WireGuard VPN integration.</li> <li>Environment Management: Uses Devbox to handle binaries like <code>k0sctl</code>, <code>kubectl</code>, <code>task</code>, and other necessary CLI tools.</li> </ul>"},{"location":"cluster/k0s/#installation","title":"\ud83d\udee0\ufe0f Installation","text":""},{"location":"cluster/k0s/#prerequisites","title":"\ud83d\udccc Prerequisites","text":"<p>Before installing the cluster, ensure you have:</p> <ul> <li>A server with a compatible Linux distribution (Ubuntu/Debian recommended)</li> <li>SSH access with a key (<code>~/.ssh/id_rsa</code>)</li> <li>Devbox installed to manage required tools:   <pre><code>curl -fsSL https://get.jetify.com/devbox | bash\n</code></pre></li> <li>Set up the environment using Devbox:   <pre><code>devbox add k0sctl kubectl go-task\n</code></pre></li> <li>Launch your devbox shell:   <pre><code>devbox shell\n</code></pre></li> </ul>"},{"location":"cluster/k0s/#deploying-the-cluster","title":"\ud83d\ude80 Deploying the Cluster","text":"<ol> <li>Check your k0sctl file</li> </ol> <p>file should be in <code>infra/k0s/fullstack.yaml</code></p> <ol> <li>Verify the configuration and start the installation</li> </ol> <pre><code>task apply-config\n</code></pre> <p>This ensures everything is ready before actual deployment ans ask for applying changes.</p> <ol> <li>Verify that the cluster is active <pre><code>task kubeconf\nkubectl get nodes\n</code></pre></li> </ol>"},{"location":"cluster/k0s/#technical-configuration-details","title":"\u2699\ufe0f Technical Configuration Details","text":""},{"location":"cluster/k0s/#1-networking-configuration","title":"1\ufe0f\u20e3 Networking Configuration","text":"<ul> <li>CNI Used: <code>kube-router</code></li> <li>Hairpin Mode Enabled: Allows pods to communicate via their own IP address.</li> <li>iptables Mode for kube-proxy: Ensures better compatibility with existing networking setups.</li> </ul>"},{"location":"cluster/k0s/#2-security-sysctls","title":"2\ufe0f\u20e3 Security &amp; Sysctls","text":"<p>Certain advanced <code>sysctls</code> are enabled to enhance routing management, particularly for WireGuard VPN tunnels:</p> <pre><code>--allowed-unsafe-sysctls=net.ipv4.ip_forward,net.ipv4.conf.all.src_valid_mark\n</code></pre> <ul> <li><code>net.ipv4.ip_forward</code>: Enables packet forwarding, required for VPN and overlay networks.</li> <li><code>net.ipv4.conf.all.src_valid_mark</code>: Ensures proper routing of encrypted WireGuard packets.</li> </ul>"},{"location":"cluster/k0s/#3-disabled-components","title":"3\ufe0f\u20e3 Disabled Components","text":"<p>Some unnecessary components for a home lab are disabled to reduce resource usage and improve stability:</p> <ul> <li>Autopilot (automatic updates management, not needed here)</li> <li>Helm (not required since charts can be managed separately)</li> <li>Windows-node (no Windows support required)</li> <li>Konnectivity-server (used for complex networks, unnecessary here)</li> </ul>"},{"location":"cluster/k0s/#4-data-storage","title":"4\ufe0f\u20e3 Data Storage","text":"<ul> <li>The Kubernetes state storage is managed by Kine, a lightweight alternative to <code>etcd</code>, using SQLite or a remote database.</li> <li>This reduces resource consumption and avoids the complexity of running an etcd cluster on a single node.</li> </ul>"},{"location":"cluster/k0s/#cluster-management","title":"\ud83d\udd04 Cluster Management","text":""},{"location":"cluster/k0s/#check-the-controller","title":"\ud83c\udfd7\ufe0f Check the controller","text":"<pre><code>ssh fred@192.168.1.190 \"sudo systemctl status k0scontroller.service\"\n</code></pre>"},{"location":"cluster/k0s/#access-the-cluster","title":"\ud83d\ude80 Access the Cluster","text":"<pre><code>export KUBECONFIG=$(task kubeconf)\nkubectl get nodes\n</code></pre>"},{"location":"cluster/k0s/#upgrading-k0s","title":"\ud83d\udd27 Upgrading k0s","text":"<p>To upgrade k0s to the latest stable version:</p> <pre><code>task upgrade-cluster\n</code></pre>"},{"location":"cluster/k0s/#backing-up-the-cluster","title":"\ud83d\udd04 Backing Up the Cluster","text":"<p>To create a backup of the cluster:</p> <pre><code>task backup\n</code></pre>"}]}